{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49597c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:09.926557Z",
     "iopub.status.busy": "2025-11-29T12:03:09.926310Z",
     "iopub.status.idle": "2025-11-29T12:03:15.248926Z",
     "shell.execute_reply": "2025-11-29T12:03:15.248336Z"
    },
    "papermill": {
     "duration": 5.330387,
     "end_time": "2025-11-29T12:03:15.250256",
     "exception": false,
     "start_time": "2025-11-29T12:03:09.919869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ca040a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:15.259928Z",
     "iopub.status.busy": "2025-11-29T12:03:15.259570Z",
     "iopub.status.idle": "2025-11-29T12:03:23.642109Z",
     "shell.execute_reply": "2025-11-29T12:03:23.641247Z"
    },
    "papermill": {
     "duration": 8.388962,
     "end_time": "2025-11-29T12:03:23.643606",
     "exception": false,
     "start_time": "2025-11-29T12:03:15.254644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.8)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.15.3)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.3)\r\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.12.4)\r\n",
      "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.24)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.12.0.88)\r\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.5)\r\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.5.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2.4.1)\r\n",
      "Collecting numpy>=1.24.4 (from albumentations)\r\n",
      "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.41.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->albumentations) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "INFO: pip is looking at multiple versions of mkl-fft to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting mkl_fft (from numpy>=1.24.4->albumentations)\r\n",
      "  Downloading mkl_fft-2.1.1-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.3 kB)\r\n",
      "  Downloading mkl_fft-2.0.0-22-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.1 kB)\r\n",
      "INFO: pip is looking at multiple versions of mkl-random to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting mkl_random (from numpy>=1.24.4->albumentations)\r\n",
      "  Downloading mkl_random-1.3.0-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\r\n",
      "  Downloading mkl_random-1.2.11-22-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\r\n",
      "INFO: pip is looking at multiple versions of mkl-umath to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting mkl_umath (from numpy>=1.24.4->albumentations)\r\n",
      "  Downloading mkl_umath-0.3.0-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "  Downloading mkl_umath-0.2.0-21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\r\n",
      "Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: numpy\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed numpy-2.2.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7de6380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:23.655907Z",
     "iopub.status.busy": "2025-11-29T12:03:23.655370Z",
     "iopub.status.idle": "2025-11-29T12:03:24.242486Z",
     "shell.execute_reply": "2025-11-29T12:03:24.241659Z"
    },
    "papermill": {
     "duration": 0.594954,
     "end_time": "2025-11-29T12:03:24.243953",
     "exception": false,
     "start_time": "2025-11-29T12:03:23.648999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd.variable as Variable\n",
    "\n",
    "from glob import glob\n",
    "from math import sqrt\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, batch_size, input_shape=(3, 84, 84), std=0.05):\n",
    "        super(GaussianNoise, self).__init__()\n",
    "        self.shape = (batch_size,) + input_shape\n",
    "        self.noise = Variable(torch.zeros(self.shape).cuda())\n",
    "        self.std = std\n",
    "\n",
    "    def forward(self, x, std=0.15):\n",
    "        noise = Variable(torch.zeros(x.shape).cuda())\n",
    "        noise = noise.data.normal_(0, std=std)\n",
    "        return x + noise\n",
    "\n",
    "\n",
    "def set_gpu(x):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = x\n",
    "    print('using gpu:', x)\n",
    "\n",
    "\n",
    "def clone(tensor):\n",
    "    \"\"\"Detach and clone a tensor including the ``requires_grad`` attribute.\n",
    "\n",
    "    Arguments:\n",
    "        tensor (torch.Tensor): tensor to clone.\n",
    "    \"\"\"\n",
    "    cloned = tensor.clone()#tensor.detach().clone()\n",
    "    # cloned.requires_grad = tensor.requires_grad\n",
    "    # if tensor.grad is not None:\n",
    "    #     cloned.grad = clone(tensor.grad)\n",
    "    return cloned\n",
    "\n",
    "def clone_state_dict(state_dict):\n",
    "    \"\"\"Clone a state_dict. If state_dict is from a ``torch.nn.Module``, use ``keep_vars=True``.\n",
    "\n",
    "    Arguments:\n",
    "        state_dict (OrderedDict): the state_dict to clone. Assumes state_dict is not detached from model state.\n",
    "    \"\"\"\n",
    "    return OrderedDict([(name, clone(param)) for name, param in state_dict.items()])\n",
    "\n",
    "def ensure_path(path):\n",
    "    if os.path.exists(path):\n",
    "        if input('{} exists, remove? ([y]/n)'.format(path)) != 'n':\n",
    "            shutil.rmtree(path)\n",
    "            os.mkdir(path)\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "\n",
    "class Averager():\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.v = 0\n",
    "\n",
    "    def add(self, x):\n",
    "        self.v = (self.v * self.n + x) / (self.n + 1)\n",
    "        self.n += 1\n",
    "\n",
    "    def item(self):\n",
    "        return self.v\n",
    "\n",
    "def count_acc(logits, label):\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    return (pred == label).type(torch.cuda.FloatTensor).mean().item()\n",
    "\n",
    "def dot_metric(a, b):\n",
    "    return torch.mm(a, b.t())\n",
    "\n",
    "def euclidean_metric(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    a = a.unsqueeze(1).expand(n, m, -1)\n",
    "    b = b.unsqueeze(0).expand(n, m, -1)\n",
    "    logits = -((a - b)**2).sum(dim=2)\n",
    "    return logits\n",
    "\n",
    "class Timer():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.o = time.time()\n",
    "\n",
    "    def measure(self, p=1):\n",
    "        x = (time.time() - self.o) / p\n",
    "        x = int(x)\n",
    "        if x >= 3600:\n",
    "            return '{:.1f}h'.format(x / 3600)\n",
    "        if x >= 60:\n",
    "            return '{}m'.format(round(x / 60))\n",
    "        return '{}s'.format(x)\n",
    "\n",
    "_utils_pp = pprint.PrettyPrinter()\n",
    "def pprint(x):\n",
    "    _utils_pp.pprint(x)\n",
    "\n",
    "def l2_loss(pred, label):\n",
    "    return ((pred - label)**2).sum() / len(pred) / 2\n",
    "\n",
    "def set_protocol(data_path, protocol, test_protocol, subset=None):\n",
    "    train = []\n",
    "    val = []\n",
    "    all_set = ['shn', 'hon', 'clv', 'clk', 'gls', 'scl', 'sci', 'nat', 'shx', 'rel']\n",
    "    if subset is not None:\n",
    "        train.append(data_path + '/crops_' + subset + '/')\n",
    "        val.append(data_path + '/crops_' + subset + '/')\n",
    "    if protocol == 'p1':\n",
    "        for i in range(3):\n",
    "            train.append(data_path + '/crops_' + all_set[i])\n",
    "    elif protocol == 'p2':\n",
    "        for i in range(3, 6):\n",
    "            train.append(data_path + '/crops_' + all_set[i])\n",
    "    elif protocol == 'p3':\n",
    "        for i in range(6, 8):\n",
    "            train.append(data_path + '/crops_' + all_set[i])\n",
    "    elif protocol == 'p4':\n",
    "        for i in range(8, 10):\n",
    "            train.append(data_path + '/crops_' + all_set[i])\n",
    "\n",
    "    if test_protocol == 'p1':\n",
    "        for i in range(3):\n",
    "            val.append(data_path + '/crops_' + all_set[i])\n",
    "    elif test_protocol == 'p2':\n",
    "        for i in range(3, 6):\n",
    "            val.append(data_path + '/crops_' + all_set[i])\n",
    "    elif test_protocol == 'p3':\n",
    "        for i in range(6, 8):\n",
    "            val.append(data_path + '/crops_' + all_set[i])\n",
    "    elif test_protocol == 'p4':\n",
    "        for i in range(8, 10):\n",
    "            val.append(data_path + '/crops_' + all_set[i])\n",
    "    return train, val\n",
    "\n",
    "def flip(x, dim):\n",
    "    dim = x.dim() + dim if dim < 0 else dim\n",
    "    return x[tuple(slice(None, None) if i != dim\n",
    "             else torch.arange(x.size(i)-1, -1, -1).long()\n",
    "             for i in range(x.dim()))]\n",
    "\n",
    "def perturb(data):\n",
    "    randno = np.random.randint(0, 5)\n",
    "    if randno == 1:\n",
    "        return torch.cat((data, data.flip(3)), dim=0)\n",
    "    elif randno == 2: #180\n",
    "        return torch.cat((data, data.flip(2)), dim=0)\n",
    "    elif randno == 3: #90\n",
    "        return torch.cat((data, data.transpose(2,3)), dim=0)\n",
    "    else:\n",
    "        return torch.cat((data, data.transpose(2, 3).flip(3)), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd8882",
   "metadata": {
    "papermill": {
     "duration": 0.00488,
     "end_time": "2025-11-29T12:03:24.254022",
     "exception": false,
     "start_time": "2025-11-29T12:03:24.249142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb7741f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:24.265601Z",
     "iopub.status.busy": "2025-11-29T12:03:24.265161Z",
     "iopub.status.idle": "2025-11-29T12:03:24.269619Z",
     "shell.execute_reply": "2025-11-29T12:03:24.269007Z"
    },
    "papermill": {
     "duration": 0.011735,
     "end_time": "2025-11-29T12:03:24.270737",
     "exception": false,
     "start_time": "2025-11-29T12:03:24.259002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "cd '/kaggle/working/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b3e1dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:24.282410Z",
     "iopub.status.busy": "2025-11-29T12:03:24.281790Z",
     "iopub.status.idle": "2025-11-29T12:03:33.677607Z",
     "shell.execute_reply": "2025-11-29T12:03:33.676654Z"
    },
    "papermill": {
     "duration": 9.402747,
     "end_time": "2025-11-29T12:03:33.678837",
     "exception": false,
     "start_time": "2025-11-29T12:03:24.276090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning all image paths...\n",
      "Found 50330 total images after filtering out Pepper classes.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Gather All Data ---\n",
    "print(\"Scanning all image paths...\")\n",
    "all_paths_raw = glob(\"/kaggle/input/plantvillage-dataset/color/*/*.JPG\")\n",
    "\n",
    "# Filter out problematic Pepper classes\n",
    "all_paths = []\n",
    "for path in all_paths_raw:\n",
    "    if 'Pepper,_bell___healthy' in path or 'Pepper,_bell___Bacterial_spot' in path:\n",
    "        continue  # Skip these classes\n",
    "    label = path.split('/')[-2]  # Extract class name from path\n",
    "    all_paths.append([path, label])\n",
    "\n",
    "print(f\"Found {len(all_paths)} total images after filtering out Pepper classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5da7774f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:33.690916Z",
     "iopub.status.busy": "2025-11-29T12:03:33.690630Z",
     "iopub.status.idle": "2025-11-29T12:03:33.718305Z",
     "shell.execute_reply": "2025-11-29T12:03:33.717365Z"
    },
    "papermill": {
     "duration": 0.035242,
     "end_time": "2025-11-29T12:03:33.719520",
     "exception": false,
     "start_time": "2025-11-29T12:03:33.684278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/8913517.py:56: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5.0, 15.0), p=0.1),\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "leaf_train_augmentation = A.Compose([\n",
    "    # spatial\n",
    "    A.RandomResizedCrop(size=(84, 84), scale=(0.7, 1.0), ratio=(0.75, 1.33), p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.3),\n",
    "    A.Rotate(limit=180, p=0.7, border_mode=0),\n",
    "    A.Perspective(scale=(0.05, 0.1), p=0.4),\n",
    "\n",
    "    # color / lighting\n",
    "    A.OneOf([\n",
    "        # controlled color jitter\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02, p=1.0),\n",
    "        # HSV shifts: explicit shift limits (degrees for hue, percent for saturation/value)\n",
    "        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=1.0),\n",
    "        # random brightness/contrast\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
    "    ], p=0.9),\n",
    "\n",
    "    # Apply either gamma, CLAHE or tone curve (kept), but not all every time\n",
    "    A.OneOf([\n",
    "        A.RandomGamma(gamma_limit=(80,120), p=1.0),\n",
    "        A.CLAHE(clip_limit=2.0, tile_grid_size=(8,8), p=1.0),\n",
    "        A.RandomToneCurve(p=1.0),\n",
    "    ], p=0.6),\n",
    "\n",
    "    # final normalization + tensor conversion\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "leaf_smart_augmentation = A.Compose([\n",
    "    # Conservative spatial transforms\n",
    "    A.Resize(92, 92),  # Slightly larger then crop\n",
    "    A.RandomCrop(84, 84, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.3),  # Small rotations\n",
    "    \n",
    "    # Color variations that mimic real-world conditions\n",
    "    A.OneOf([\n",
    "        # Lighting changes\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=1.0),\n",
    "        # Color temperature variations\n",
    "        A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=1.0),\n",
    "    ], p=0.6),\n",
    "    \n",
    "    # Mild noise for sensor variations\n",
    "    A.GaussNoise(var_limit=(5.0, 15.0), p=0.1),\n",
    "    \n",
    "    # Focus on preserving texture details\n",
    "    A.Sharpen(alpha=(0.05, 0.1), lightness=(0.8, 1.0), p=0.1),  # Very mild sharpening\n",
    "    \n",
    "    # Normalize\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "leaf_val_augmentation = A.Compose([\n",
    "    A.Resize(96, 96),  # Slightly larger\n",
    "    A.CenterCrop(84, 84),  # Clean center crop\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "leaf_finetune_augmentation = A.Compose([\n",
    "    A.RandomResizedCrop(size=(84, 84), scale=(0.85, 1.0), ratio=(0.9, 1.1), p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=45, p=0.5, border_mode=0),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.7),\n",
    "    A.GaussianBlur(blur_limit=(3, 5), p=0.15),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# UPDATED DATASET CLASS\n",
    "# ========================================\n",
    "class UiSmell(Dataset):\n",
    "    def __init__(self, setname, img_path, is_aug=False):\n",
    "        csv_path = osp.join('/kaggle/working/materials/', setname + '.csv')\n",
    "        lines = [x.strip() for x in open(csv_path, 'r').readlines()][1:]\n",
    "        self.is_aug = is_aug\n",
    "        self.img_path = img_path\n",
    "\n",
    "        data, label = [], []\n",
    "        label_map, label_counter = {}, 0\n",
    "\n",
    "        for line in lines:\n",
    "            name, lbl = line.split(',', 1)\n",
    "            lbl_clean = lbl.strip()\n",
    "            if lbl_clean not in label_map:\n",
    "                label_map[lbl_clean] = label_counter\n",
    "                label_counter += 1\n",
    "            path = osp.join(img_path, name)\n",
    "            data.append(path)\n",
    "            label.append(label_map[lbl_clean])\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.label_map = label_map\n",
    "\n",
    "        if is_aug:\n",
    "            self.transform = leaf_train_augmentation\n",
    "            print(f\"✅ Using STRONG leaf augmentation for {setname}\")\n",
    "        else:\n",
    "            self.transform = leaf_val_augmentation\n",
    "            print(f\"✅ Using VALIDATION augmentation for {setname}\")\n",
    "\n",
    "        print(f\"Loaded {len(self.data)} samples with {len(self.label_map)} classes for {setname}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.data[index]\n",
    "        label = self.label[index]\n",
    "\n",
    "        # PIL -> NumPy (H,W,C)\n",
    "        image = np.array(Image.open(path).convert('RGB'))\n",
    "\n",
    "        # Apply albumentations\n",
    "        augmented = self.transform(image=image)\n",
    "        image = augmented['image']  # torch.Tensor from ToTensorV2\n",
    "\n",
    "        # Ensure float32 (should already be)\n",
    "        if not torch.is_floating_point(image):\n",
    "            image = image.float()\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be02a728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:33.731072Z",
     "iopub.status.busy": "2025-11-29T12:03:33.730817Z",
     "iopub.status.idle": "2025-11-29T12:03:33.734235Z",
     "shell.execute_reply": "2025-11-29T12:03:33.733471Z"
    },
    "papermill": {
     "duration": 0.010409,
     "end_time": "2025-11-29T12:03:33.735393",
     "exception": false,
     "start_time": "2025-11-29T12:03:33.724984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"/kaggle/working/materials/train.csv\")\n",
    "# df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0530f80c",
   "metadata": {
    "papermill": {
     "duration": 0.005183,
     "end_time": "2025-11-29T12:03:33.746042",
     "exception": false,
     "start_time": "2025-11-29T12:03:33.740859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0700eb2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:33.758279Z",
     "iopub.status.busy": "2025-11-29T12:03:33.757731Z",
     "iopub.status.idle": "2025-11-29T12:03:33.764234Z",
     "shell.execute_reply": "2025-11-29T12:03:33.763494Z"
    },
    "papermill": {
     "duration": 0.014203,
     "end_time": "2025-11-29T12:03:33.765316",
     "exception": false,
     "start_time": "2025-11-29T12:03:33.751113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CategoriesSampler():\n",
    "\n",
    "    def __init__(self, label, n_batch, n_cls, n_per):\n",
    "        self.n_batch = n_batch\n",
    "        self.n_cls = n_cls\n",
    "        self.n_per = n_per\n",
    "\n",
    "        label = np.array(label)\n",
    "        self.m_ind = []\n",
    "        for i in range(max(label) + 1):\n",
    "            ind = np.argwhere(label == i).reshape(-1)\n",
    "            ind = torch.from_numpy(ind)\n",
    "            if len(ind) > 4:\n",
    "                self.m_ind.append(ind)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batch\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i_batch in range(self.n_batch):\n",
    "            batch = []\n",
    "            classes = torch.randperm(len(self.m_ind))[:self.n_cls]\n",
    "            for c in classes:\n",
    "                l = self.m_ind[c]\n",
    "                pos = torch.randperm(len(l))[:self.n_per]\n",
    "                batch.append(l[pos])\n",
    "            batch = torch.stack(batch).t().reshape(-1)\n",
    "            #for i in range(1000):\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3279bc",
   "metadata": {
    "papermill": {
     "duration": 0.004971,
     "end_time": "2025-11-29T12:03:33.775415",
     "exception": false,
     "start_time": "2025-11-29T12:03:33.770444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f0ab19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:33.786650Z",
     "iopub.status.busy": "2025-11-29T12:03:33.786164Z",
     "iopub.status.idle": "2025-11-29T12:03:36.915432Z",
     "shell.execute_reply": "2025-11-29T12:03:36.914416Z"
    },
    "papermill": {
     "duration": 3.136703,
     "end_time": "2025-11-29T12:03:36.916992",
     "exception": false,
     "start_time": "2025-11-29T12:03:33.780289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6c5f20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:36.928899Z",
     "iopub.status.busy": "2025-11-29T12:03:36.928449Z",
     "iopub.status.idle": "2025-11-29T12:03:36.935408Z",
     "shell.execute_reply": "2025-11-29T12:03:36.934701Z"
    },
    "papermill": {
     "duration": 0.014069,
     "end_time": "2025-11-29T12:03:36.936522",
     "exception": false,
     "start_time": "2025-11-29T12:03:36.922453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CategoriesSampler():\n",
    "\n",
    "    def __init__(self, label, n_batch, n_cls, n_per):\n",
    "        self.n_batch = n_batch\n",
    "        self.n_cls = n_cls\n",
    "        self.n_per = n_per\n",
    "\n",
    "        label = np.array(label)\n",
    "        self.m_ind = []\n",
    "        for i in range(max(label) + 1):\n",
    "            ind = np.argwhere(label == i).reshape(-1)\n",
    "            ind = torch.from_numpy(ind)\n",
    "            if len(ind) > 4:\n",
    "                self.m_ind.append(ind)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batch\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i_batch in range(self.n_batch):\n",
    "            batch = []\n",
    "            classes = torch.randperm(len(self.m_ind))[:self.n_cls]\n",
    "            for c in classes:\n",
    "                l = self.m_ind[c]\n",
    "                pos = torch.randperm(len(l))[:self.n_per]\n",
    "                batch.append(l[pos])\n",
    "            batch = torch.stack(batch).t().reshape(-1)\n",
    "            #for i in range(1000):\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2d7022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:36.947697Z",
     "iopub.status.busy": "2025-11-29T12:03:36.947505Z",
     "iopub.status.idle": "2025-11-29T12:03:36.959264Z",
     "shell.execute_reply": "2025-11-29T12:03:36.958700Z"
    },
    "papermill": {
     "duration": 0.018775,
     "end_time": "2025-11-29T12:03:36.960381",
     "exception": false,
     "start_time": "2025-11-29T12:03:36.941606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_ch, mid_ch, stride=1, alpha=0.1):\n",
    "        super().__init__()\n",
    "        out_ch = mid_ch * 4\n",
    "        self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(mid_ch)\n",
    "        self.conv2 = nn.Conv2d(mid_ch, mid_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(mid_ch)\n",
    "        self.conv3 = nn.Conv2d(mid_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.bn3   = nn.BatchNorm2d(out_ch)\n",
    "        self.act   = nn.LeakyReLU(alpha, inplace=True)\n",
    "        self.short = nn.Sequential()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.short = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        identity = self.short(x) if len(self.short) else x\n",
    "        out = self.act(self.bn1(self.conv1(x)))\n",
    "        out = self.act(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = self.act(out + identity)\n",
    "        return out\n",
    "\n",
    "class ResNet50Plus(nn.Module):\n",
    "    def __init__(self, num_classes, alpha=0.1, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(alpha, inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.layer1 = self._make_layer(64,   64, blocks=3, stride=1, alpha=alpha)\n",
    "        self.layer2 = self._make_layer(256, 128, blocks=4, stride=2, alpha=alpha)\n",
    "        self.layer3 = self._make_layer(512, 256, blocks=6, stride=2, alpha=alpha)\n",
    "        self.layer4 = self._make_layer(1024,512, blocks=3, stride=2, alpha=alpha)\n",
    "        self.avg    = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.head   = nn.Sequential(nn.Flatten(), nn.Dropout(dropout_p), nn.Linear(2048, num_classes))\n",
    "\n",
    "    def _make_layer(self, in_ch, mid_ch, blocks, stride, alpha):\n",
    "        layers = [Bottleneck(in_ch, mid_ch, stride=stride, alpha=alpha)]\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(Bottleneck(mid_ch*4, mid_ch, stride=1, alpha=alpha))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x); x = self.layer2(x); x = self.layer3(x); x = self.layer4(x)\n",
    "        x = self.avg(x); x = self.head(x)\n",
    "        return x\n",
    "\n",
    "# -------------------\n",
    "# MixUp helpers\n",
    "# -------------------\n",
    "def mixup_batch(x, y, alpha=0.2):\n",
    "    if alpha is None or alpha <= 0:\n",
    "        return x, (y, y, 1.0)\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0), device=x.device)\n",
    "    x_mix = lam * x + (1 - lam) * x[idx]\n",
    "    return x_mix, (y, y[idx], lam)\n",
    "\n",
    "def mixup_criterion(ce_loss, preds, targets):\n",
    "    y_a, y_b, lam = targets\n",
    "    return lam * ce_loss(preds, y_a) + (1 - lam) * ce_loss(preds, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575189f",
   "metadata": {
    "papermill": {
     "duration": 0.004894,
     "end_time": "2025-11-29T12:03:36.970499",
     "exception": false,
     "start_time": "2025-11-29T12:03:36.965605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a3280e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:36.981566Z",
     "iopub.status.busy": "2025-11-29T12:03:36.981355Z",
     "iopub.status.idle": "2025-11-29T12:03:36.992150Z",
     "shell.execute_reply": "2025-11-29T12:03:36.991555Z"
    },
    "papermill": {
     "duration": 0.0179,
     "end_time": "2025-11-29T12:03:36.993368",
     "exception": false,
     "start_time": "2025-11-29T12:03:36.975468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Subspace_Projection(nn.Module):\n",
    "    def __init__(self, num_dim=2, debug=False, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.num_dim = num_dim\n",
    "        self.debug = debug\n",
    "        self.eps = eps  # Better numerical stability\n",
    "\n",
    "    def create_subspace(self, supportset_features, class_size, sample_size):\n",
    "        # Add validation\n",
    "        if sample_size < self.num_dim + 1:\n",
    "            self.num_dim = sample_size - 1\n",
    "            print(f\"Warning: Reduced subspace dim to {self.num_dim}\")\n",
    "        all_hyper_planes = []\n",
    "        means = []\n",
    "        for ii in range(class_size):\n",
    "            all_support = supportset_features[ii]\n",
    "            mean_vec = torch.mean(all_support, dim=0)\n",
    "            means.append(mean_vec)\n",
    "            centered = all_support - mean_vec.unsqueeze(0)\n",
    "            uu, s, v = torch.svd(centered.transpose(0, 1).double(), some=False)\n",
    "            uu = uu.float()\n",
    "            all_hyper_planes.append(uu[:, :self.num_dim])  # limit dimension!\n",
    "\n",
    "        all_hyper_planes = torch.stack(all_hyper_planes, dim=0)\n",
    "        means = torch.stack(means, dim=0)\n",
    "        return all_hyper_planes, means\n",
    "\n",
    "    def projection_metric(self, target_features, hyperplanes, mu):\n",
    "        eps = 1e-12\n",
    "        device = target_features.device\n",
    "        batch_size = target_features.shape[0]\n",
    "        class_size = hyperplanes.shape[0]\n",
    "\n",
    "        similarities = []\n",
    "        discriminative_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "        for j in range(class_size):\n",
    "            h_plane_j = hyperplanes[j].unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
    "            tf_centered = (target_features - mu[j].expand_as(target_features)).unsqueeze(-1)\n",
    "            proj = torch.bmm(h_plane_j, torch.bmm(h_plane_j.transpose(1, 2), tf_centered))\n",
    "            proj = torch.squeeze(proj, -1) + mu[j].unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "            diff = target_features - proj\n",
    "            query_loss = -torch.sqrt(torch.sum(diff * diff, dim=-1) + eps)\n",
    "            similarities.append(query_loss)\n",
    "\n",
    "            # discriminative term (reduced)\n",
    "            for k in range(class_size):\n",
    "                if j != k:\n",
    "                    temp = torch.mm(hyperplanes[j].T, hyperplanes[k])\n",
    "                    discriminative_loss += torch.sum(temp * temp)\n",
    "\n",
    "        similarities = torch.stack(similarities, dim=1).to(device)\n",
    "        class_size = hyperplanes.shape[0]\n",
    "        discriminative_loss = discriminative_loss / (class_size * (class_size - 1) + 1e-6)\n",
    "        similarities = similarities / similarities.std(dim=1, keepdim=True).clamp_min(1e-6)\n",
    "\n",
    "        # ---- DEBUG ----\n",
    "        if self.debug:\n",
    "            print(\"[DEBUG] projection_metric DEBUG:\")\n",
    "            print(f\"  target_features: mean={target_features.mean():.6f}, std={target_features.std():.6f}\")\n",
    "            print(f\"  hyperplanes: mean={hyperplanes.mean():.6f}, std={hyperplanes.std():.6f}\")\n",
    "            print(f\"  similarities: mean={similarities.mean():.6f}, std={similarities.std():.6f}, min={similarities.min():.6f}, max={similarities.max():.6f}\")\n",
    "            print(f\"  discriminative_loss: {discriminative_loss.item():.6f}\")\n",
    "\n",
    "        return similarities, discriminative_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0076aa3",
   "metadata": {
    "papermill": {
     "duration": 0.005054,
     "end_time": "2025-11-29T12:03:37.003762",
     "exception": false,
     "start_time": "2025-11-29T12:03:36.998708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b07bf10d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:37.014833Z",
     "iopub.status.busy": "2025-11-29T12:03:37.014303Z",
     "iopub.status.idle": "2025-11-29T12:03:37.508128Z",
     "shell.execute_reply": "2025-11-29T12:03:37.507258Z"
    },
    "papermill": {
     "duration": 0.500985,
     "end_time": "2025-11-29T12:03:37.509538",
     "exception": false,
     "start_time": "2025-11-29T12:03:37.008553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from datetime import datetime\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# SET MODEL NAME\n",
    "modelname = 'ResNet50Plus'\n",
    "\n",
    "args = {}\n",
    "args['num_sampler'] = 500\n",
    "args['max-epoch'] = 25\n",
    "args['save-epoch'] = 5\n",
    "args['shot'] = 5\n",
    "args['query'] = 5\n",
    "args['train-way'] = 5\n",
    "args['test-way'] = 5\n",
    "args['data-path'] = '/kaggle/input/plantvillage-dataset/color/'\n",
    "args['gpu'] = '0'\n",
    "args['lamb'] = 0.5\n",
    "args['lr'] = 1e-4\n",
    "args['weight_decay'] = 1e-4\n",
    "args['subspace-dim'] = args['shot']-1  # For shot=5, dim=4\n",
    "set_gpu(args['gpu'])\n",
    "\n",
    "txt = str(datetime.now())\n",
    "txt = '_'.join([modelname+f\"-{args['shot']}-{args['lamb']}-{args['lr']}-{args['num_sampler']}\", txt[:4], txt[5:7], txt[8:10], txt[11:13], txt[14:16]])\n",
    "\n",
    "args['save-path'] = '/kaggle/working/save/'+txt\n",
    "\n",
    "# MODEL BUILDER\n",
    "model = {\n",
    "    'ResNet50Plus': ResNet50Plus(num_classes=512),\n",
    "}[modelname].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98f33cd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:37.521067Z",
     "iopub.status.busy": "2025-11-29T12:03:37.520787Z",
     "iopub.status.idle": "2025-11-29T12:03:37.524562Z",
     "shell.execute_reply": "2025-11-29T12:03:37.523819Z"
    },
    "papermill": {
     "duration": 0.010594,
     "end_time": "2025-11-29T12:03:37.525661",
     "exception": false,
     "start_time": "2025-11-29T12:03:37.515067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from glob import glob\n",
    "import random\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2395856b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:37.536762Z",
     "iopub.status.busy": "2025-11-29T12:03:37.536561Z",
     "iopub.status.idle": "2025-11-29T12:03:38.038148Z",
     "shell.execute_reply": "2025-11-29T12:03:38.037169Z"
    },
    "papermill": {
     "duration": 0.508849,
     "end_time": "2025-11-29T12:03:38.039501",
     "exception": false,
     "start_time": "2025-11-29T12:03:37.530652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning all image paths...\n",
      "Found 50330 total images and corrected labels in memory.\n",
      "Found 36 unique classes.\n",
      "Splitting classes into: 25 train, 5 validation, 6 test.\n",
      "Class splits are successfully disjoint.\n",
      "Final data splits (number of images): Train=31333, Val=10138, Test=8859\n",
      "\n",
      "CSV files with diverse and corrected data splits created successfully inside 'materials' folder.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Gather All Data ---\n",
    "print(\"Scanning all image paths...\")\n",
    "all_paths_raw = glob(\"/kaggle/input/plantvillage-dataset/color/*/*.JPG\")\n",
    "\n",
    "print(f\"Found {len(all_paths)} total images and corrected labels in memory.\")\n",
    "\n",
    "# --- Step 2: Identify All Unique Classes ---\n",
    "all_labels = [label for path, label in all_paths]\n",
    "unique_classes = sorted(list(set(all_labels)))\n",
    "random.seed(42) # for reproducibility\n",
    "random.shuffle(unique_classes)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"Found {num_classes} unique classes.\")\n",
    "\n",
    "# --- Step 3: Split the *Classes* into Disjoint Sets ---\n",
    "train_split = int(0.7 * num_classes)\n",
    "val_split = int(0.15 * num_classes)\n",
    "\n",
    "train_classes = unique_classes[:train_split]\n",
    "val_classes = unique_classes[train_split : train_split + val_split]\n",
    "test_classes = unique_classes[train_split + val_split:]\n",
    "\n",
    "print(f\"Splitting classes into: {len(train_classes)} train, {len(val_classes)} validation, {len(test_classes)} test.\")\n",
    "\n",
    "# Sanity check: ensure the class sets are disjoint (no overlap)\n",
    "assert len(set(train_classes) & set(val_classes)) == 0\n",
    "assert len(set(train_classes) & set(test_classes)) == 0\n",
    "assert len(set(val_classes) & set(test_classes)) == 0\n",
    "print(\"Class splits are successfully disjoint.\")\n",
    "\n",
    "\n",
    "# --- Step 4: Create Final Data Lists ---\n",
    "paths_train, paths_val, paths_test = [], [], []\n",
    "\n",
    "for path, label in all_paths:\n",
    "    if label in train_classes:\n",
    "        paths_train.append([path, label])\n",
    "    elif label in val_classes:\n",
    "        paths_val.append([path, label])\n",
    "    else:\n",
    "        paths_test.append([path, label])\n",
    "\n",
    "print(f\"Final data splits (number of images): Train={len(paths_train)}, Val={len(paths_val)}, Test={len(paths_test)}\")\n",
    "\n",
    "\n",
    "# --- Step 5: Write the new CSV files ---\n",
    "data = {'train': paths_train,\n",
    "        'test': paths_test,\n",
    "        'val': paths_val,\n",
    "}\n",
    "\n",
    "os.makedirs(\"/kaggle/working/materials\", exist_ok=True)\n",
    "csv_files = [\"train.csv\", \"test.csv\", \"val.csv\"]\n",
    "\n",
    "for fname in csv_files:\n",
    "    path = os.path.join(\"/kaggle/working/materials\", fname)\n",
    "    with open(path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"filename\", \"label\"])\n",
    "        writer.writerows(data[fname[:-4]])\n",
    "\n",
    "print(\"\\nCSV files with diverse and corrected data splits created successfully inside 'materials' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc1d99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:38.051697Z",
     "iopub.status.busy": "2025-11-29T12:03:38.051303Z",
     "iopub.status.idle": "2025-11-29T12:03:38.124112Z",
     "shell.execute_reply": "2025-11-29T12:03:38.123174Z"
    },
    "papermill": {
     "duration": 0.080131,
     "end_time": "2025-11-29T12:03:38.125474",
     "exception": false,
     "start_time": "2025-11-29T12:03:38.045343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using STRONG leaf augmentation for train\n",
      "Loaded 31333 samples with 25 classes for train\n",
      "✅ Using VALIDATION augmentation for val\n",
      "Loaded 10138 samples with 5 classes for val\n",
      "✅ Using VALIDATION augmentation for test\n",
      "Loaded 8859 samples with 6 classes for test\n",
      "=== All Classes and Their Labels ===\n",
      "Label 0: Tomato___Late_blight\n",
      "Label 1: Tomato___healthy\n",
      "Label 2: Soybean___healthy\n",
      "Label 3: Potato___healthy\n",
      "Label 4: Corn_(maize)___Northern_Leaf_Blight\n",
      "Label 5: Tomato___Early_blight\n",
      "Label 6: Tomato___Septoria_leaf_spot\n",
      "Label 7: Strawberry___Leaf_scorch\n",
      "Label 8: Apple___Apple_scab\n",
      "Label 9: Tomato___Bacterial_spot\n",
      "Label 10: Cherry_(including_sour)___Powdery_mildew\n",
      "Label 11: Peach___Bacterial_spot\n",
      "Label 12: Apple___Cedar_apple_rust\n",
      "Label 13: Tomato___Target_Spot\n",
      "Label 14: Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "Label 15: Potato___Late_blight\n",
      "Label 16: Tomato___Tomato_mosaic_virus\n",
      "Label 17: Strawberry___healthy\n",
      "Label 18: Grape___Black_rot\n",
      "Label 19: Potato___Early_blight\n",
      "Label 20: Cherry_(including_sour)___healthy\n",
      "Label 21: Corn_(maize)___Common_rust_\n",
      "Label 22: Grape___Esca_(Black_Measles)\n",
      "Label 23: Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Label 24: Corn_(maize)___healthy\n",
      "\n",
      "=== Classes in Order ===\n",
      "0: Tomato___Late_blight\n",
      "1: Tomato___healthy\n",
      "2: Soybean___healthy\n",
      "3: Potato___healthy\n",
      "4: Corn_(maize)___Northern_Leaf_Blight\n",
      "5: Tomato___Early_blight\n",
      "6: Tomato___Septoria_leaf_spot\n",
      "7: Strawberry___Leaf_scorch\n",
      "8: Apple___Apple_scab\n",
      "9: Tomato___Bacterial_spot\n",
      "10: Cherry_(including_sour)___Powdery_mildew\n",
      "11: Peach___Bacterial_spot\n",
      "12: Apple___Cedar_apple_rust\n",
      "13: Tomato___Target_Spot\n",
      "14: Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "15: Potato___Late_blight\n",
      "16: Tomato___Tomato_mosaic_virus\n",
      "17: Strawberry___healthy\n",
      "18: Grape___Black_rot\n",
      "19: Potato___Early_blight\n",
      "20: Cherry_(including_sour)___healthy\n",
      "21: Corn_(maize)___Common_rust_\n",
      "22: Grape___Esca_(Black_Measles)\n",
      "23: Tomato___Spider_mites Two-spotted_spider_mite\n",
      "24: Corn_(maize)___healthy\n"
     ]
    }
   ],
   "source": [
    "# First, create the datasets\n",
    "trainset = UiSmell('train', '/kaggle/input/plantvillage-dataset/color/', is_aug=True)\n",
    "valset = UiSmell('val', '/kaggle/input/plantvillage-dataset/color/', is_aug=False)\n",
    "testset = UiSmell('test', '/kaggle/input/plantvillage-dataset/color/', is_aug=False)\n",
    "\n",
    "# Now you can print the classes\n",
    "print(\"=== All Classes and Their Labels ===\")\n",
    "for class_name, label_id in trainset.label_map.items():\n",
    "    print(f\"Label {label_id}: {class_name}\")\n",
    "\n",
    "print(\"\\n=== Classes in Order ===\")\n",
    "sorted_classes = sorted(trainset.label_map.items(), key=lambda x: x[1])\n",
    "for class_name, label_id in sorted_classes:\n",
    "    print(f\"{label_id}: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaae7609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:38.137518Z",
     "iopub.status.busy": "2025-11-29T12:03:38.137316Z",
     "iopub.status.idle": "2025-11-29T12:03:38.222696Z",
     "shell.execute_reply": "2025-11-29T12:03:38.221737Z"
    },
    "papermill": {
     "duration": 0.092716,
     "end_time": "2025-11-29T12:03:38.223927",
     "exception": false,
     "start_time": "2025-11-29T12:03:38.131211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using STRONG leaf augmentation for train\n",
      "Loaded 31333 samples with 25 classes for train\n",
      "✅ Using VALIDATION augmentation for val\n",
      "Loaded 10138 samples with 5 classes for val\n",
      "✅ Using VALIDATION augmentation for test\n",
      "Loaded 8859 samples with 6 classes for test\n"
     ]
    }
   ],
   "source": [
    "# DATA LOADER\n",
    "trainset = UiSmell('train', args['data-path'], is_aug=True)\n",
    "train_sampler = CategoriesSampler(trainset.label, args['num_sampler'],\n",
    "                                  args['train-way'], args['shot'] + args['query'])\n",
    "train_loader = DataLoader(dataset=trainset, batch_sampler=train_sampler, shuffle=False,)\n",
    "\n",
    "valset = UiSmell('val', args['data-path'], is_aug=False)\n",
    "val_sampler = CategoriesSampler(valset.label, args['num_sampler'],\n",
    "                                args['test-way'], args['shot'] + args['query'])\n",
    "val_loader = DataLoader(dataset=valset, batch_sampler=val_sampler, shuffle=False,)\n",
    "\n",
    "testset = UiSmell('test', args['data-path'], is_aug=False)\n",
    "test_sampler = CategoriesSampler(testset.label, args['num_sampler'],\n",
    "                                args['test-way'], args['shot'] + args['query'])\n",
    "test_loader = DataLoader(dataset=testset, batch_sampler=test_sampler, shuffle=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a985fe43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:38.236751Z",
     "iopub.status.busy": "2025-11-29T12:03:38.236351Z",
     "iopub.status.idle": "2025-11-29T12:03:38.242805Z",
     "shell.execute_reply": "2025-11-29T12:03:38.242124Z"
    },
    "papermill": {
     "duration": 0.014147,
     "end_time": "2025-11-29T12:03:38.243852",
     "exception": false,
     "start_time": "2025-11-29T12:03:38.229705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created classes.txt at: /kaggle/working/materials/classes.txt\n",
      "\\n--- Class Names (in order) ---\n",
      "0: Tomato___Late_blight\n",
      "1: Tomato___healthy\n",
      "2: Soybean___healthy\n",
      "3: Potato___healthy\n",
      "4: Corn_(maize)___Northern_Leaf_Blight\n",
      "5: Tomato___Early_blight\n",
      "6: Tomato___Septoria_leaf_spot\n",
      "7: Strawberry___Leaf_scorch\n",
      "8: Apple___Apple_scab\n",
      "9: Tomato___Bacterial_spot\n",
      "10: Cherry_(including_sour)___Powdery_mildew\n",
      "11: Peach___Bacterial_spot\n",
      "12: Apple___Cedar_apple_rust\n",
      "13: Tomato___Target_Spot\n",
      "14: Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "15: Potato___Late_blight\n",
      "16: Tomato___Tomato_mosaic_virus\n",
      "17: Strawberry___healthy\n",
      "18: Grape___Black_rot\n",
      "19: Potato___Early_blight\n",
      "20: Cherry_(including_sour)___healthy\n",
      "21: Corn_(maize)___Common_rust_\n",
      "22: Grape___Esca_(Black_Measles)\n",
      "23: Tomato___Spider_mites Two-spotted_spider_mite\n",
      "24: Corn_(maize)___healthy\n"
     ]
    }
   ],
   "source": [
    "label_map = trainset.label_map\n",
    "sorted_items = sorted(label_map.items(), key=lambda item: item[1])\n",
    "\n",
    "# Extract the class names in the now correct order\n",
    "class_names_ordered = [item[0] for item in sorted_items]\n",
    "\n",
    "# Define the output path for the class names file\n",
    "output_path = '/kaggle/working/materials/classes.txt'\n",
    "\n",
    "# Write the ordered class names to the file, one per line\n",
    "with open(output_path, 'w') as f:\n",
    "    for name in class_names_ordered:\n",
    "        f.write(f\"{name}\\n\")\n",
    "\n",
    "print(f\"Successfully created classes.txt at: {output_path}\")\n",
    "print(\"\\\\n--- Class Names (in order) ---\")\n",
    "for i, name in enumerate(class_names_ordered):\n",
    "    print(f\"{i}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98cb9535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:38.256286Z",
     "iopub.status.busy": "2025-11-29T12:03:38.256077Z",
     "iopub.status.idle": "2025-11-29T12:03:38.366897Z",
     "shell.execute_reply": "2025-11-29T12:03:38.366146Z"
    },
    "papermill": {
     "duration": 0.118615,
     "end_time": "2025-11-29T12:03:38.368145",
     "exception": false,
     "start_time": "2025-11-29T12:03:38.249530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transform (is_aug): True\n",
      "transform output keys: dict_keys(['image'])\n",
      "image type from transform: <class 'torch.Tensor'> shape: torch.Size([3, 84, 84])\n"
     ]
    }
   ],
   "source": [
    "# run in your notebook\n",
    "print(\"Using transform (is_aug):\", trainset.is_aug)\n",
    "sample_path = trainset.data[0]\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "img = np.array(Image.open(sample_path).convert('RGB'))\n",
    "out = trainset.transform(image=img)\n",
    "print(\"transform output keys:\", out.keys())\n",
    "print(\"image type from transform:\", type(out['image']), \"shape:\", getattr(out['image'], 'shape', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33aff6dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:38.380759Z",
     "iopub.status.busy": "2025-11-29T12:03:38.380212Z",
     "iopub.status.idle": "2025-11-29T12:03:38.511161Z",
     "shell.execute_reply": "2025-11-29T12:03:38.510384Z"
    },
    "papermill": {
     "duration": 0.138275,
     "end_time": "2025-11-29T12:03:38.512394",
     "exception": false,
     "start_time": "2025-11-29T12:03:38.374119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Augmented image (what model sees)')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = out['image']  # torch.Tensor C,H,W\n",
    "img_vis = t.permute(1,2,0).cpu().numpy()\n",
    "mean = np.array([0.485,0.456,0.406])\n",
    "std  = np.array([0.229,0.224,0.225])\n",
    "img_vis = np.clip(img_vis * std + mean, 0, 1)\n",
    "plt.imshow(img_vis); plt.axis('off'); plt.title('Augmented image (what model sees)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd13c890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:38.526246Z",
     "iopub.status.busy": "2025-11-29T12:03:38.525950Z",
     "iopub.status.idle": "2025-11-29T12:03:38.530023Z",
     "shell.execute_reply": "2025-11-29T12:03:38.529307Z"
    },
    "papermill": {
     "duration": 0.012182,
     "end_time": "2025-11-29T12:03:38.531185",
     "exception": false,
     "start_time": "2025-11-29T12:03:38.519003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albumentations version: 2.0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"albumentations version:\", A.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57e4839a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:03:38.544884Z",
     "iopub.status.busy": "2025-11-29T12:03:38.544654Z",
     "iopub.status.idle": "2025-11-29T15:14:02.375138Z",
     "shell.execute_reply": "2025-11-29T15:14:02.374214Z"
    },
    "papermill": {
     "duration": 11423.839161,
     "end_time": "2025-11-29T15:14:02.376407",
     "exception": false,
     "start_time": "2025-11-29T12:03:38.537246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using STRONG leaf augmentation for train\n",
      "Loaded 31333 samples with 25 classes for train\n",
      "✅ Using VALIDATION augmentation for val\n",
      "Loaded 10138 samples with 5 classes for val\n",
      "✅ Using VALIDATION augmentation for test\n",
      "Loaded 8859 samples with 6 classes for test\n",
      "\n",
      "========================================\n",
      "STARTING TRAINING FOR 1-SHOT\n",
      "========================================\n",
      "\n",
      "Saving results to: /kaggle/working/save/ResNet50Plus_Shot1_20251129_1203\n",
      "[Shot 1] Epoch 1: Train Loss=1.7945 Acc=0.2426 | Val Loss=1.5941 Acc=0.3310\n",
      "[Shot 1] Epoch 2: Train Loss=1.6355 Acc=0.3090 | Val Loss=1.4815 Acc=0.4257\n",
      "[Shot 1] Epoch 3: Train Loss=1.4882 Acc=0.3874 | Val Loss=1.3889 Acc=0.4298\n",
      "[Shot 1] Epoch 4: Train Loss=1.3603 Acc=0.4504 | Val Loss=1.3492 Acc=0.4574\n",
      "[Shot 1] Epoch 5: Train Loss=1.2932 Acc=0.4827 | Val Loss=1.3863 Acc=0.4590\n",
      "[Shot 1] Epoch 6: Train Loss=1.2429 Acc=0.5140 | Val Loss=1.4234 Acc=0.4491\n",
      "[Shot 1] Epoch 7: Train Loss=1.1720 Acc=0.5534 | Val Loss=1.2530 Acc=0.5342\n",
      "[Shot 1] Epoch 8: Train Loss=1.1309 Acc=0.5770 | Val Loss=1.2848 Acc=0.5360\n",
      "[Shot 1] Epoch 9: Train Loss=1.0886 Acc=0.6036 | Val Loss=1.3395 Acc=0.4887\n",
      "[Shot 1] Epoch 10: Train Loss=1.0623 Acc=0.6157 | Val Loss=1.2779 Acc=0.5252\n",
      "[Shot 1] Epoch 11: Train Loss=1.0481 Acc=0.6217 | Val Loss=1.2344 Acc=0.5537\n",
      "[Shot 1] Epoch 12: Train Loss=1.0054 Acc=0.6526 | Val Loss=1.2339 Acc=0.5432\n",
      "[Shot 1] Epoch 13: Train Loss=1.0038 Acc=0.6449 | Val Loss=1.2711 Acc=0.5253\n",
      "[Shot 1] Epoch 14: Train Loss=0.9694 Acc=0.6667 | Val Loss=1.1532 Acc=0.5783\n",
      "[Shot 1] Epoch 15: Train Loss=0.9489 Acc=0.6807 | Val Loss=1.3035 Acc=0.5342\n",
      "[Shot 1] Epoch 16: Train Loss=0.9276 Acc=0.6916 | Val Loss=1.2963 Acc=0.5311\n",
      "[Shot 1] Epoch 17: Train Loss=0.9240 Acc=0.6922 | Val Loss=1.2544 Acc=0.5270\n",
      "[Shot 1] Epoch 18: Train Loss=0.8713 Acc=0.7273 | Val Loss=1.2320 Acc=0.5494\n",
      "[Shot 1] Epoch 19: Train Loss=0.8367 Acc=0.7464 | Val Loss=1.2294 Acc=0.5396\n",
      "Early stopping at epoch 19\n",
      "Testing best model for 1-Shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 500it [00:40, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: 1-Shot Test Accuracy: 0.7241\n",
      "\n",
      "========================================\n",
      "STARTING TRAINING FOR 2-SHOT\n",
      "========================================\n",
      "\n",
      "Saving results to: /kaggle/working/save/ResNet50Plus_Shot2_20251129_1229\n",
      "[Shot 2] Epoch 1: Train Loss=1.6481 Acc=0.3181 | Val Loss=1.2510 Acc=0.5007\n",
      "[Shot 2] Epoch 2: Train Loss=1.3345 Acc=0.4810 | Val Loss=1.1494 Acc=0.5683\n",
      "[Shot 2] Epoch 3: Train Loss=1.2319 Acc=0.5324 | Val Loss=1.1018 Acc=0.6120\n",
      "[Shot 2] Epoch 4: Train Loss=1.1521 Acc=0.5789 | Val Loss=1.1184 Acc=0.6125\n",
      "[Shot 2] Epoch 5: Train Loss=1.1269 Acc=0.5995 | Val Loss=1.0546 Acc=0.6441\n",
      "[Shot 2] Epoch 6: Train Loss=1.0359 Acc=0.6446 | Val Loss=1.0196 Acc=0.6592\n",
      "[Shot 2] Epoch 7: Train Loss=0.9797 Acc=0.6828 | Val Loss=1.0173 Acc=0.6605\n",
      "[Shot 2] Epoch 8: Train Loss=0.9576 Acc=0.6913 | Val Loss=0.9794 Acc=0.6957\n",
      "[Shot 2] Epoch 9: Train Loss=0.9356 Acc=0.7035 | Val Loss=1.0443 Acc=0.6531\n",
      "[Shot 2] Epoch 10: Train Loss=0.8713 Acc=0.7478 | Val Loss=1.0376 Acc=0.6524\n",
      "[Shot 2] Epoch 11: Train Loss=0.8513 Acc=0.7517 | Val Loss=1.0801 Acc=0.6415\n",
      "[Shot 2] Epoch 12: Train Loss=0.8202 Acc=0.7687 | Val Loss=1.0194 Acc=0.6485\n",
      "[Shot 2] Epoch 13: Train Loss=0.7953 Acc=0.7867 | Val Loss=0.9155 Acc=0.7026\n",
      "[Shot 2] Epoch 14: Train Loss=0.7810 Acc=0.7948 | Val Loss=1.0220 Acc=0.6613\n",
      "[Shot 2] Epoch 15: Train Loss=0.7432 Acc=0.8150 | Val Loss=1.0080 Acc=0.6638\n",
      "[Shot 2] Epoch 16: Train Loss=0.7323 Acc=0.8229 | Val Loss=0.9742 Acc=0.6865\n",
      "[Shot 2] Epoch 17: Train Loss=0.7442 Acc=0.8148 | Val Loss=0.9306 Acc=0.6883\n",
      "[Shot 2] Epoch 18: Train Loss=0.7201 Acc=0.8307 | Val Loss=0.9064 Acc=0.7227\n",
      "[Shot 2] Epoch 19: Train Loss=0.6867 Acc=0.8470 | Val Loss=1.0194 Acc=0.6464\n",
      "[Shot 2] Epoch 20: Train Loss=0.6618 Acc=0.8585 | Val Loss=1.0399 Acc=0.6414\n",
      "[Shot 2] Epoch 21: Train Loss=0.6298 Acc=0.8770 | Val Loss=0.9198 Acc=0.7070\n",
      "[Shot 2] Epoch 22: Train Loss=0.6179 Acc=0.8833 | Val Loss=0.9023 Acc=0.7137\n",
      "[Shot 2] Epoch 23: Train Loss=0.6118 Acc=0.8850 | Val Loss=0.8929 Acc=0.7110\n",
      "Early stopping at epoch 23\n",
      "Testing best model for 2-Shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 500it [00:29, 17.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: 2-Shot Test Accuracy: 0.7774\n",
      "\n",
      "========================================\n",
      "STARTING TRAINING FOR 3-SHOT\n",
      "========================================\n",
      "\n",
      "Saving results to: /kaggle/working/save/ResNet50Plus_Shot3_20251129_1258\n",
      "[Shot 3] Epoch 1: Train Loss=1.5409 Acc=0.3778 | Val Loss=1.1710 Acc=0.5772\n",
      "[Shot 3] Epoch 2: Train Loss=1.2654 Acc=0.5266 | Val Loss=0.9688 Acc=0.6915\n",
      "[Shot 3] Epoch 3: Train Loss=1.1524 Acc=0.5916 | Val Loss=0.9959 Acc=0.6969\n",
      "[Shot 3] Epoch 4: Train Loss=1.0994 Acc=0.6176 | Val Loss=0.9580 Acc=0.7001\n",
      "[Shot 3] Epoch 5: Train Loss=1.0178 Acc=0.6757 | Val Loss=0.9204 Acc=0.7280\n",
      "[Shot 3] Epoch 6: Train Loss=0.9680 Acc=0.7025 | Val Loss=0.9281 Acc=0.7154\n",
      "[Shot 3] Epoch 7: Train Loss=0.9388 Acc=0.7232 | Val Loss=0.9710 Acc=0.6871\n",
      "[Shot 3] Epoch 8: Train Loss=0.8994 Acc=0.7447 | Val Loss=0.8556 Acc=0.7558\n",
      "[Shot 3] Epoch 9: Train Loss=0.8527 Acc=0.7712 | Val Loss=0.9982 Acc=0.6742\n",
      "[Shot 3] Epoch 10: Train Loss=0.8367 Acc=0.7776 | Val Loss=0.9058 Acc=0.7250\n",
      "[Shot 3] Epoch 11: Train Loss=0.8135 Acc=0.7901 | Val Loss=0.8984 Acc=0.7309\n",
      "[Shot 3] Epoch 12: Train Loss=0.7862 Acc=0.8038 | Val Loss=0.9104 Acc=0.7206\n",
      "[Shot 3] Epoch 13: Train Loss=0.7580 Acc=0.8194 | Val Loss=0.8988 Acc=0.7356\n",
      "Early stopping at epoch 13\n",
      "Testing best model for 3-Shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 500it [00:28, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: 3-Shot Test Accuracy: 0.7632\n",
      "\n",
      "========================================\n",
      "STARTING TRAINING FOR 4-SHOT\n",
      "========================================\n",
      "\n",
      "Saving results to: /kaggle/working/save/ResNet50Plus_Shot4_20251129_1315\n",
      "[Shot 4] Epoch 1: Train Loss=1.5514 Acc=0.3829 | Val Loss=1.0383 Acc=0.6580\n",
      "[Shot 4] Epoch 2: Train Loss=1.2353 Acc=0.5481 | Val Loss=0.9813 Acc=0.6934\n",
      "[Shot 4] Epoch 3: Train Loss=1.1467 Acc=0.5997 | Val Loss=0.8883 Acc=0.7487\n",
      "[Shot 4] Epoch 4: Train Loss=1.0713 Acc=0.6547 | Val Loss=0.9058 Acc=0.7438\n",
      "[Shot 4] Epoch 5: Train Loss=1.0077 Acc=0.6919 | Val Loss=0.9276 Acc=0.7249\n",
      "[Shot 4] Epoch 6: Train Loss=0.9486 Acc=0.7228 | Val Loss=0.8670 Acc=0.7323\n",
      "[Shot 4] Epoch 7: Train Loss=0.9136 Acc=0.7429 | Val Loss=0.9050 Acc=0.7266\n",
      "[Shot 4] Epoch 8: Train Loss=0.8860 Acc=0.7586 | Val Loss=0.8389 Acc=0.7595\n",
      "[Shot 4] Epoch 9: Train Loss=0.8296 Acc=0.7947 | Val Loss=0.8760 Acc=0.7452\n",
      "[Shot 4] Epoch 10: Train Loss=0.7919 Acc=0.8130 | Val Loss=0.8900 Acc=0.7335\n",
      "[Shot 4] Epoch 11: Train Loss=0.7659 Acc=0.8246 | Val Loss=0.8735 Acc=0.7523\n",
      "[Shot 4] Epoch 12: Train Loss=0.7529 Acc=0.8326 | Val Loss=0.7817 Acc=0.7989\n",
      "[Shot 4] Epoch 13: Train Loss=0.7389 Acc=0.8381 | Val Loss=0.8321 Acc=0.7630\n",
      "[Shot 4] Epoch 14: Train Loss=0.7291 Acc=0.8471 | Val Loss=0.8324 Acc=0.7666\n",
      "[Shot 4] Epoch 15: Train Loss=0.7029 Acc=0.8599 | Val Loss=0.8667 Acc=0.7494\n",
      "[Shot 4] Epoch 16: Train Loss=0.6923 Acc=0.8645 | Val Loss=0.8151 Acc=0.7875\n",
      "[Shot 4] Epoch 17: Train Loss=0.6605 Acc=0.8830 | Val Loss=0.8341 Acc=0.7558\n",
      "Early stopping at epoch 17\n",
      "Testing best model for 4-Shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 500it [00:30, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: 4-Shot Test Accuracy: 0.8420\n",
      "\n",
      "========================================\n",
      "STARTING TRAINING FOR 5-SHOT\n",
      "========================================\n",
      "\n",
      "Saving results to: /kaggle/working/save/ResNet50Plus_Shot5_20251129_1342\n",
      "[Shot 5] Epoch 1: Train Loss=1.5677 Acc=0.3868 | Val Loss=1.0348 Acc=0.6756\n",
      "[Shot 5] Epoch 2: Train Loss=1.2124 Acc=0.5744 | Val Loss=0.9222 Acc=0.7318\n",
      "[Shot 5] Epoch 3: Train Loss=1.0905 Acc=0.6460 | Val Loss=0.9018 Acc=0.7406\n",
      "[Shot 5] Epoch 4: Train Loss=1.0473 Acc=0.6757 | Val Loss=0.9146 Acc=0.7290\n",
      "[Shot 5] Epoch 5: Train Loss=0.9926 Acc=0.7099 | Val Loss=0.8659 Acc=0.7499\n",
      "[Shot 5] Epoch 6: Train Loss=0.9367 Acc=0.7436 | Val Loss=0.8331 Acc=0.7765\n",
      "[Shot 5] Epoch 7: Train Loss=0.8976 Acc=0.7638 | Val Loss=0.8410 Acc=0.7646\n",
      "[Shot 5] Epoch 8: Train Loss=0.8657 Acc=0.7834 | Val Loss=0.8341 Acc=0.7739\n",
      "[Shot 5] Epoch 9: Train Loss=0.8269 Acc=0.8022 | Val Loss=0.8660 Acc=0.7498\n",
      "[Shot 5] Epoch 10: Train Loss=0.7962 Acc=0.8182 | Val Loss=0.8276 Acc=0.7807\n",
      "[Shot 5] Epoch 11: Train Loss=0.7824 Acc=0.8290 | Val Loss=0.7980 Acc=0.7991\n",
      "[Shot 5] Epoch 12: Train Loss=0.7529 Acc=0.8407 | Val Loss=0.8392 Acc=0.7729\n",
      "[Shot 5] Epoch 13: Train Loss=0.7255 Acc=0.8553 | Val Loss=0.8194 Acc=0.7803\n",
      "[Shot 5] Epoch 14: Train Loss=0.7319 Acc=0.8510 | Val Loss=0.7688 Acc=0.8031\n",
      "[Shot 5] Epoch 15: Train Loss=0.7020 Acc=0.8684 | Val Loss=0.7740 Acc=0.8045\n",
      "[Shot 5] Epoch 16: Train Loss=0.6829 Acc=0.8768 | Val Loss=0.7974 Acc=0.7890\n",
      "[Shot 5] Epoch 17: Train Loss=0.6742 Acc=0.8836 | Val Loss=0.7391 Acc=0.8270\n",
      "[Shot 5] Epoch 18: Train Loss=0.6524 Acc=0.8934 | Val Loss=0.8091 Acc=0.7879\n",
      "[Shot 5] Epoch 19: Train Loss=0.6558 Acc=0.8918 | Val Loss=0.7889 Acc=0.7929\n",
      "[Shot 5] Epoch 20: Train Loss=0.6439 Acc=0.8973 | Val Loss=0.7563 Acc=0.8062\n",
      "[Shot 5] Epoch 21: Train Loss=0.5905 Acc=0.9206 | Val Loss=0.6600 Acc=0.8638\n",
      "[Shot 5] Epoch 22: Train Loss=0.5751 Acc=0.9264 | Val Loss=0.6912 Acc=0.8426\n",
      "[Shot 5] Epoch 23: Train Loss=0.5776 Acc=0.9217 | Val Loss=0.6749 Acc=0.8576\n",
      "[Shot 5] Epoch 24: Train Loss=0.5607 Acc=0.9343 | Val Loss=0.6692 Acc=0.8575\n",
      "[Shot 5] Epoch 25: Train Loss=0.5493 Acc=0.9391 | Val Loss=0.7108 Acc=0.8395\n",
      "Testing best model for 5-Shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 500it [00:34, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: 5-Shot Test Accuracy: 0.8758\n",
      "\n",
      "========================================\n",
      "STARTING TRAINING FOR 10-SHOT\n",
      "========================================\n",
      "\n",
      "Saving results to: /kaggle/working/save/ResNet50Plus_Shot10_20251129_1422\n",
      "[Shot 10] Epoch 1: Train Loss=1.5538 Acc=0.4397 | Val Loss=0.8900 Acc=0.7580\n",
      "[Shot 10] Epoch 2: Train Loss=1.2547 Acc=0.6150 | Val Loss=0.8501 Acc=0.7905\n",
      "[Shot 10] Epoch 3: Train Loss=1.1659 Acc=0.6637 | Val Loss=0.8243 Acc=0.8077\n",
      "[Shot 10] Epoch 4: Train Loss=1.1167 Acc=0.7006 | Val Loss=0.8323 Acc=0.7914\n",
      "[Shot 10] Epoch 5: Train Loss=1.0699 Acc=0.7269 | Val Loss=0.7893 Acc=0.8174\n",
      "[Shot 10] Epoch 6: Train Loss=1.0048 Acc=0.7570 | Val Loss=0.8249 Acc=0.7918\n",
      "[Shot 10] Epoch 7: Train Loss=0.9664 Acc=0.7846 | Val Loss=0.7895 Acc=0.8216\n",
      "[Shot 10] Epoch 8: Train Loss=0.9415 Acc=0.7914 | Val Loss=0.7669 Acc=0.8319\n",
      "[Shot 10] Epoch 9: Train Loss=0.9206 Acc=0.8082 | Val Loss=0.7614 Acc=0.8193\n",
      "[Shot 10] Epoch 10: Train Loss=0.8975 Acc=0.8196 | Val Loss=0.7155 Acc=0.8474\n",
      "[Shot 10] Epoch 11: Train Loss=0.8689 Acc=0.8354 | Val Loss=0.7315 Acc=0.8440\n",
      "[Shot 10] Epoch 12: Train Loss=0.8232 Acc=0.8584 | Val Loss=0.7111 Acc=0.8530\n",
      "[Shot 10] Epoch 13: Train Loss=0.8029 Acc=0.8674 | Val Loss=0.6920 Acc=0.8608\n",
      "[Shot 10] Epoch 14: Train Loss=0.8049 Acc=0.8622 | Val Loss=0.7586 Acc=0.8262\n",
      "[Shot 10] Epoch 15: Train Loss=0.7777 Acc=0.8779 | Val Loss=0.7216 Acc=0.8471\n",
      "[Shot 10] Epoch 16: Train Loss=0.7489 Acc=0.8894 | Val Loss=0.6842 Acc=0.8770\n",
      "[Shot 10] Epoch 17: Train Loss=0.7406 Acc=0.8922 | Val Loss=0.6739 Acc=0.8734\n",
      "[Shot 10] Epoch 18: Train Loss=0.7148 Acc=0.9054 | Val Loss=0.6687 Acc=0.8816\n",
      "[Shot 10] Epoch 19: Train Loss=0.7088 Acc=0.9092 | Val Loss=0.6900 Acc=0.8623\n",
      "[Shot 10] Epoch 20: Train Loss=0.6956 Acc=0.9126 | Val Loss=0.6872 Acc=0.8853\n",
      "[Shot 10] Epoch 21: Train Loss=0.6483 Acc=0.9324 | Val Loss=0.6506 Acc=0.8858\n",
      "[Shot 10] Epoch 22: Train Loss=0.6290 Acc=0.9386 | Val Loss=0.6404 Acc=0.8850\n",
      "[Shot 10] Epoch 23: Train Loss=0.6242 Acc=0.9408 | Val Loss=0.6590 Acc=0.8838\n",
      "[Shot 10] Epoch 24: Train Loss=0.6190 Acc=0.9426 | Val Loss=0.6511 Acc=0.8846\n",
      "[Shot 10] Epoch 25: Train Loss=0.6038 Acc=0.9474 | Val Loss=0.6386 Acc=0.9006\n",
      "Testing best model for 10-Shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 500it [00:47, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: 10-Shot Test Accuracy: 0.9106\n",
      "\n",
      "ALL EXPERIMENTS COMPLETED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# --- GLOBAL CONFIGURATION ---\n",
    "modelname = 'ResNet50Plus'\n",
    "shots_to_train = [1, 2, 3, 4, 5, 10]  # The list of shots requested\n",
    "\n",
    "# Initialize Datasets ONCE to save loading time (Samplers will be rebuilt per shot)\n",
    "# Assuming UiSmell and CategoriesSampler classes are already defined in previous cells\n",
    "trainset = UiSmell('train', args['data-path'], is_aug=True)\n",
    "valset = UiSmell('val', args['data-path'], is_aug=False)\n",
    "testset = UiSmell('test', args['data-path'], is_aug=False)\n",
    "\n",
    "def run_experiment(shot_count):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"STARTING TRAINING FOR {shot_count}-SHOT\")\n",
    "    print(f\"{'='*40}\\n\")\n",
    "\n",
    "    # 1. UPDATE ARGUMENTS SPECIFIC TO THIS SHOT\n",
    "    current_args = args.copy()\n",
    "    current_args['shot'] = shot_count\n",
    "    \n",
    "    # Subspace dim rule: must be < support_size. \n",
    "    # If shot=1, code artificially doubles support to 2, so dim=1. \n",
    "    # If shot>1, dim = shot - 1.\n",
    "    current_args['subspace-dim'] = 1 if shot_count == 1 else (shot_count - 1)\n",
    "    \n",
    "    # Create unique save path\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "    run_id = f\"{modelname}_Shot{shot_count}_{timestamp}\"\n",
    "    current_args['save-path'] = osp.join('/kaggle/working/save/', run_id)\n",
    "    \n",
    "    if not os.path.exists(current_args['save-path']):\n",
    "        os.makedirs(current_args['save-path'])\n",
    "        \n",
    "    print(f\"Saving results to: {current_args['save-path']}\")\n",
    "\n",
    "    # 2. RE-INITIALIZE DATALOADERS (Batch structure depends on shot count)\n",
    "    train_sampler = CategoriesSampler(trainset.label, current_args['num_sampler'],\n",
    "                                      current_args['train-way'], current_args['shot'] + current_args['query'])\n",
    "    train_loader = DataLoader(dataset=trainset, batch_sampler=train_sampler, num_workers=2, pin_memory=True)\n",
    "\n",
    "    val_sampler = CategoriesSampler(valset.label, current_args['num_sampler'],\n",
    "                                    current_args['test-way'], current_args['shot'] + current_args['query'])\n",
    "    val_loader = DataLoader(dataset=valset, batch_sampler=val_sampler, num_workers=2, pin_memory=True)\n",
    "\n",
    "    test_sampler = CategoriesSampler(testset.label, current_args['num_sampler'],\n",
    "                                     current_args['test-way'], current_args['shot'] + current_args['query'])\n",
    "    test_loader = DataLoader(dataset=testset, batch_sampler=test_sampler, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # 3. RE-INITIALIZE MODEL & OPTIMIZER (From Scratch)\n",
    "    model = ResNet50Plus(num_classes=512).cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=current_args['lr'])\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "    projection_pro = Subspace_Projection(num_dim=current_args['subspace-dim'], debug=False)\n",
    "\n",
    "    # Logging structures\n",
    "    trlog = {\n",
    "        'train_loss': [], 'val_loss': [], 'test_loss': [],\n",
    "        'train_acc': [], 'val_acc': [], 'test_acc': [],\n",
    "        'max_acc': 0.0, 'max_epoch': 0\n",
    "    }\n",
    "    \n",
    "    timer = Timer()\n",
    "    patience = 5  # Increased slightly for stability\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Helper to save within the function\n",
    "    def save_model_local(name):\n",
    "        torch.save(model.state_dict(), osp.join(current_args['save-path'], name + '.pth'))\n",
    "\n",
    "    # --- MAIN EPOCH LOOP ---\n",
    "    for epoch in range(1, current_args['max-epoch'] + 1):\n",
    "        model.train()\n",
    "        \n",
    "        # Calculate actual support size (handling the flip for 1-shot)\n",
    "        shot_num = current_args['shot'] * 2 if current_args['shot'] == 1 else current_args['shot']\n",
    "\n",
    "        tl = Averager()\n",
    "        ta = Averager()\n",
    "\n",
    "        # Training Phase\n",
    "        for i, batch in enumerate(train_loader, 1):\n",
    "            data, _ = [_.cuda() for _ in batch]\n",
    "            \n",
    "            p = current_args['shot'] * current_args['train-way']\n",
    "            qq = p + current_args['query'] * current_args['train-way']\n",
    "            data_shot, data_query = data[:p], data[p:qq]\n",
    "\n",
    "            if current_args['shot'] == 1:\n",
    "                data_shot = torch.cat((data_shot, flip(data_shot, 3)), dim=0)\n",
    "\n",
    "            proto = model(data_shot)\n",
    "            proto = proto.reshape(shot_num, current_args['train-way'], -1)\n",
    "            proto = torch.transpose(proto, 0, 1)\n",
    "            hyperplanes, mu = projection_pro.create_subspace(proto, current_args['train-way'], shot_num)\n",
    "\n",
    "            label = torch.arange(current_args['train-way']).repeat(current_args['query'])\n",
    "            label = label.type(torch.cuda.LongTensor)\n",
    "\n",
    "            query_features = model(data_query)\n",
    "            logits, discriminative_loss = projection_pro.projection_metric(query_features, hyperplanes, mu=mu)\n",
    "\n",
    "            ce_loss = F.cross_entropy(logits, label)\n",
    "            loss = ce_loss + current_args['lamb'] * discriminative_loss\n",
    "            acc = count_acc(logits, label)\n",
    "\n",
    "            tl.add(loss.item())\n",
    "            ta.add(acc)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        vl = Averager()\n",
    "        va = Averager()\n",
    "\n",
    "        for i, batch in enumerate(val_loader, 1):\n",
    "            data, _ = [_.cuda() for _ in batch]\n",
    "            p = current_args['shot'] * current_args['test-way']\n",
    "            data_shot, data_query = data[:p], data[p:]\n",
    "\n",
    "            if current_args['shot'] == 1:\n",
    "                data_shot = torch.cat((data_shot, flip(data_shot, 3)), dim=0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                proto = model(data_shot)\n",
    "                proto = proto.reshape(shot_num, current_args['test-way'], -1)\n",
    "                proto = torch.transpose(proto, 0, 1)\n",
    "                hyperplanes, mu = projection_pro.create_subspace(proto, current_args['test-way'], shot_num)\n",
    "                logits, _ = projection_pro.projection_metric(model(data_query), hyperplanes, mu=mu)\n",
    "\n",
    "            label = torch.arange(current_args['test-way']).repeat(current_args['query']).type(torch.cuda.LongTensor)\n",
    "            loss = F.cross_entropy(logits, label)\n",
    "            acc = count_acc(logits, label)\n",
    "\n",
    "            vl.add(loss.item())\n",
    "            va.add(acc)\n",
    "\n",
    "        vl = vl.item()\n",
    "        va = va.item()\n",
    "        tl = tl.item()\n",
    "        ta = ta.item()\n",
    "\n",
    "        print(f'[Shot {shot_count}] Epoch {epoch}: Train Loss={tl:.4f} Acc={ta:.4f} | Val Loss={vl:.4f} Acc={va:.4f}')\n",
    "\n",
    "        # Save Best Model\n",
    "        if va > trlog['max_acc']:\n",
    "            trlog['max_acc'] = va\n",
    "            trlog['max_epoch'] = epoch\n",
    "            save_model_local('max-acc')\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        trlog['train_loss'].append(tl)\n",
    "        trlog['train_acc'].append(ta)\n",
    "        trlog['val_loss'].append(vl)\n",
    "        trlog['val_acc'].append(va)\n",
    "\n",
    "        # Early Stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            break\n",
    "\n",
    "    # --- TEST PHASE (After Training) ---\n",
    "    print(f\"Testing best model for {shot_count}-Shot...\")\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(osp.join(current_args['save-path'], 'max-acc.pth')))\n",
    "    model.eval()\n",
    "    \n",
    "    tel = Averager()\n",
    "    tea = Averager()\n",
    "\n",
    "    for i, batch in tqdm(enumerate(test_loader, 1), desc=\"Testing\"):\n",
    "        data, _ = [_.cuda() for _ in batch]\n",
    "        p = current_args['shot'] * current_args['test-way']\n",
    "        data_shot, data_query = data[:p], data[p:]\n",
    "\n",
    "        if current_args['shot'] == 1:\n",
    "            data_shot = torch.cat((data_shot, flip(data_shot, 3)), dim=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            proto = model(data_shot)\n",
    "            proto = proto.reshape(shot_num, current_args['test-way'], -1)\n",
    "            proto = torch.transpose(proto, 0, 1)\n",
    "            hyperplanes, mu = projection_pro.create_subspace(proto, current_args['test-way'], shot_num)\n",
    "            logits, _ = projection_pro.projection_metric(model(data_query), hyperplanes, mu=mu)\n",
    "\n",
    "        label = torch.arange(current_args['test-way']).repeat(current_args['query']).type(torch.cuda.LongTensor)\n",
    "        loss = F.cross_entropy(logits, label)\n",
    "        acc = count_acc(logits, label)\n",
    "\n",
    "        tel.add(loss.item())\n",
    "        tea.add(acc)\n",
    "\n",
    "    tel = tel.item()\n",
    "    tea = tea.item()\n",
    "    trlog['test_loss'] = tel\n",
    "    trlog['test_acc'] = tea\n",
    "    \n",
    "    print(f\"RESULT: {shot_count}-Shot Test Accuracy: {tea:.4f}\")\n",
    "    \n",
    "    # Save Logs\n",
    "    with open(osp.join(current_args['save-path'], 'trlog.json'), 'w') as f:\n",
    "        json.dump(trlog, f, indent=4)\n",
    "        \n",
    "    # Cleanup memory\n",
    "    del model\n",
    "    del optimizer\n",
    "    del train_loader, val_loader, test_loader\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# --- EXECUTE EXPERIMENTS ---\n",
    "for shot in shots_to_train:\n",
    "    run_experiment(shot)\n",
    "\n",
    "print(\"\\nALL EXPERIMENTS COMPLETED.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 277323,
     "sourceId": 658267,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11458.022698,
   "end_time": "2025-11-29T15:14:04.467472",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-29T12:03:06.444774",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
